---
title: "Regression Project"
author: "Group 8"
format: html
editor: 
  markdown: 
    wrap: sentence
---

## Introduction

For decades, a secondary education has been considered the gold standard for ensuring a comfortable career and wage. In recent years however, it is becoming more and more difficult for recent graduates to find careers corresponding to their area of expertise, and therefore the wages that go with it.

We decided upon this topic as an important area of study due to the relevance of career prospects in our own lives as well as society at large. Our data is from an inbuilt RStudio package, causaldata, that originally contains 8 columns and 48445 observations, but after the removal of NA values it is reduced to 30401 data points.

Our outcome of interest is the median income of college graduates (earnings_med), 
while our predictors of interest are the degree awarded by each university (pred_degree_awarded_ipeds), 
the number of graduates actively working (count_working), those not working (count_not_working), 
year of data collection, and region of residence.The year, count working, and count not working variables
are classified as discrete numeric values, and the degree awarded and region predictors are considered categorical.
Degree awarded has 3 different observations: 1 indicates granting a less-than-two-year degree, 
2 designates primarily awarding two-year degrees, and 3 denoting a typical four-year bachelors degree or greater.

Our sed predictor, year, contains data for 2007 until 2016, 
but upon the omission of NA values it primarily encompasses years from 2007 to 2014.
The region variable was one that we generated from state level data for ease of analysis,
and it is broken down into Northeast, North Central, South, and West.
Through an exploration of the relationships between our selected predictors and median earnings
, our goal is to develop a robust and effective model for forecasting the monetary outcomes 
associated with various types of college degrees earned across the United States.

```{r}
# all of our packages
library(causaldata)
library(datasets)
library(tidyverse)
library(ggfortify)
library(MASS)
library(pheatmap)
library(car)
library(lmtest)
library(splines)
library(reshape2)
library(interactions)
library(boot)
library(simpleboot)
library(emmeans)

# the functions used in multiple places
predict_loo <- function(model) {
y <- model.frame(model)[,1]
loo_r <- residuals(model) / (1 - hatvalues(model))
return(y - loo_r)
}
rsq_loo <- function(model) {
y <- model.frame(model)[,1]
yhat <- predict_loo(model)
return(cor(y, yhat)^2)
}
p_print <- function(object){
  print(deparse(substitute(object)))
  print(object)
}
as.numeric.l <- function(list){
  if(is.factor(list)){
    list <- as.numeric(list)
  }
  return(list)
}

## cleaning
# making region match which region the state is in
scorecard$region <- state.region[match(scorecard$state_abbr, state.abb)]
# making the degree a factor
scorecard$degree <- as.factor(scorecard$pred_degree_awarded_ipeds)
scorecard <- na.omit(scorecard)
```

## Research Questions
To effectively determine the impact of count working, count not working, year,
degree awarded, and region on the median earnings of college graduates,
we outlined three research questions as a framework for our analysis:

#### 1. Does median income have a positive relationship with the proportion of working graduates?

-   $H_0$: Median income will have a positive relationship with the number of working graduates.

-   $H_A$: positive relationship and significant p-value will prove this to be true.

#### 2. Which US region contributes most to median earnings?

-   $H_0$: All regions do not differ significantly for median earnings

-   $H_A$: Eastern region will be the most significant in median earnings compared to other regions.

#### 3. Which degree length leads to higher median salary?

-   $H_0$: Median salary does not significantly differ between degree lengths.

-   $H_A$: People with 4 year degrees have higher median salaries compared to other degre

## Data Exploration

The purpose of this project is to analyze a potential relationship
between college graduates in the US and median earnings based on year, region, degree length,
and working status. Firstly, NA values were removed from the data set. States were grouped into
regions using the state.region() base R function, and the degree length was converted to a factor
with levels for simplified analysis. Additional tidying was performed utilizing gather(), where 
"employment_status" was created with the paired variable "working" listing the number of graduates
either currently working or not working. The following is a brief analysis of trends among 
selected predictors (year, employment_status (count_working and count_not_working), degree, and region) and median earnings (earnings_med).

#### Manipulate Data

```{r}
# Organize states into regions 
scorecard$region <- state.region[match(scorecard$state_abbr, state.abb)]
scorecard <- na.omit(scorecard)

# Change variable name to 'degree'
scorecard = scorecard %>%
  mutate(degree = as.factor(pred_degree_awarded_ipeds))

glimpse(scorecard)
```

#### Region Exploration

A constructed boxplot illustrates trends in median earnings for graduates based on the US region. Graduates situated in the Northeastern US have the highest median of earnings while the South has the lowest median earnings. Both the North central and western US have similar median earnings; however, western and northeastern states have a much wider distribution of earnings than southern and the North central states. Northeastern states may have higher median earnings because of an increased concentration of "prestigious" universities (ex. Ivy League) in this region; there may be a "higher" quality of education that is more sought after for employment. This observation, however, requires additional investigation.

```{r}
# Plot for Graduate Median Earnings Based on Region
scorecard %>% ggplot(aes(x = region, y = earnings_med, fill = region)) +
  geom_boxplot() +
  labs(title = "Graduate Median Earnings Based on Region",
       x = "Region",
       y = "Median Earnings" ) +
  scale_fill_brewer(palette = "Set2") +  
  theme_minimal()

# Plot for Median Earnings Based on Region
scorecard %>% 
  ggplot(aes(x = earnings_med, fill = region)) +
  geom_histogram(bins = 35, col = "black") + facet_grid(~region) +
  labs(title = "Median Earnings Based on Region",
       x = "Median Earnings") + facet_grid(~region) + theme_minimal()

```

#### Employment Status vs. Median Earnings

A scatterplot was utilized to determine the distribution of median earnings for graduates based on working status. As seen in the rightmost scatterplot, there are more working graduates than those who do not work; there are notable extremes for count_working, where at least two data points indicate more than 7,500 working graduates were earning. Working graduates seem more numerous and spread out for median earnings compared to those who did not work. Surprisingly, working and non-working graduates seem to have similarly distributed median earnings; this goes against an assumption that working graduates would have higher median salaries than those who do not work.

```{r}
# Create a new dataframe with tidy long performed on status of work
scorecard1 <- scorecard %>% gather(key = "employment_status", value = "working", c(count_not_working, count_working)) 

scorecard1 <- scorecard1 %>% mutate(employment_status = as.factor(employment_status))

# Plot for Median Earnings of Graduates Based on Employment Status
scorecard1 %>% 
  ggplot(aes(x = working, y = earnings_med, color = employment_status)) +
  geom_point() +   facet_grid(~employment_status) +
  labs(title = "Median Earnings of Graduates Based on Employment Status",
       x = "Number of Graduates",
       y = "Median Earnings") +
  scale_color_brewer(palette = "Dark2", name = "Employment Status", labels = c("Not Working", "Working")) +
  theme_minimal() +
  theme(legend.position = "top") +
  geom_smooth(method = "lm", linetype = "dashed", color = "black") 

```

#### Degree Length vs. Median Earnings

It was expected that the longer the degree length, the higher the median earnings for graduates. Those who completed an undergraduate degree or pursued further education (ex. graduate school) earned much more than those who did not; the median earnings for this group are higher, and there is more spread for median earnings. This visually supports the observation that graduates with at least an undergraduate degree or additional completed schooling have a higher chance of employment because academic and professional skills may be more developed for a selected profession. As such, preference may be given for graduates with an undergraduate degree or higher education status compared to those who have two or less years of completed education.

```{r}
# Plot for Median Earnings of Graduates Based on Degree Length
scorecard1 %>% 
  ggplot(aes(x = degree, y = earnings_med, fill = degree)) +
  geom_boxplot() +
  labs(title = "Median Earnings of Graduates Based on Degree Length",
       x = "Degree Length", y = "Median Earnings") +  theme_minimal() + scale_fill_discrete(labels=c('Less than 2 years', 'Two years', '4+ years')) + 
  scale_x_discrete(labels = c('Less than 2 years', 'Two years', '4+ years'))
```

#### Year vs. Median Earnings

Median earnings based on years did not frequently change, and years 2009 and 2011 saw at least one visible outlier among graduates for more than \$150,000 earned.
Because yearly data for 2008 and post 2014 was omitted due to missing information, the yearly earnings distribution may not be reflective of additional years. However, the trends in the boxplot indicate that median earnings generally decreased after 2009; this may indicate a response to economic effects. Additional research is required to further investigate this observation.

```{r}
# changing year to a factor
scorecard1$year_level <- as.factor(scorecard1$year)

# Plot for Median Earnings of Graduates 2007 - 2014
scorecard1 %>% 
  ggplot(aes(x = year_level, y = earnings_med, fill = year_level)) +
  geom_boxplot() +
  labs(title = "Median Earnings of Graduates 2007 - 2014",
       x = "Year", y = "Median Earnings") +  theme_minimal()
```

#### Correlations

A correlation matrix was generated to visualize correlations between selected numeric variables.The highest correlation was found to be between `count_working` and `count_not_working` at 0.97.This is trivial since the number of graduates that are able to find work directly influences the number of graduates that remained unemployed. The magnitudes of all other correlation factors were below 0.25, suggesting the variables have a quite weak relationship.

```{r}
# getting year as a numeric
scorecard$year_num <- as.numeric(scorecard$year)

# getting the heat map for the year, earnings_med, count_not_working, count_working
scorecard_cor <- cor(na.omit(scorecard[,c(5, 6, 7, 8)]))
pheatmap(scorecard_cor,
        treeheight_col = 0,
        treeheight_row = 0,
        display_numbers = TRUE,
        breaks = seq(-1, 1, length = 101))
```

## Multiple Linear Regression Model

To assess for the presence of a predictive relationship between the median earnings of individuals graduating from colleges and universities across the United States and characteristics associated with their alma mater and post college lives, we constructed a linear model regressing median earnings on surveyed universities' regional location, the number of alumni both employed and not working (not necessarily un-employed), the primary degree awarded, and the year that each survey was conducted.

```{r}
earnings_lm<-lm(earnings_med~region+degree+year+count_not_working+count_working, data=scorecard)
summary(earnings_lm)
scorecard$region<-relevel(scorecard$region, ref="Northeast")
cat("Earnings median range:", range(scorecard$earnings_med))
```

The substantial F-statistic generated by the linear model of 3691 on 8 and 30392 degrees of freedom allowed us to reject the null hypothesis that none of the chosen variables possess any relationship to median earnings (all slopes are equal to zero) in favor of the alternative hypothesis that at least one of the predictive variables influences the earnings of American college graduates (at least one slope is not equal to zero).

Given the confirmation of, at minimum, one of our independent variables' predictive power, we further explored the more nuanced ways in which each contributed to variation from the baseline predicted income of \$503,340, as denoted by the intercept regression coefficient. Holding the influence of region, degrees typically awarded, year, and the number of graduates not actively employed constant, a one person increase in the number of gainfully employed graduates contributed to an institution results in a marginal \$1.56 increase in predicted median earnings. Conversely, when controlling for the effect of all other predictors, the addition of a single non-working alumni unsurprisingly elicits a predicted \$8.86 decline in predicted income. Assessment of the regression coefficient assigned to the year variable in the same manner revealed a slightly more impactful association between the year participants were surveyed and median earnings, with the passage of one year resulting in a loss of \$235.90.

Due to the categorical nature of the predominant degree awarded by collegiate study participants and the region in which each institution of higher learning resides, the analysis of their influence on predicted monetary outcomes diverged from that of aforementioned variables. As a hub for a variety of prestigious Universities, we anticipated that graduates from Northeastern schools would likely possess the highest median earnings and we accordingly designated it as the reference for our analysis of regional impacts. When controlling for the effects of all other variables and regions, prior attendance of a Southern school resulted in an average median earnings reduction of \$4,613 from the Northeastern baseline. Upon similar evaluation, graduation from North Central and Western colleges comparably resulted in an average loss of \$3,651 and \$1,761, respectively.

In considering the impact of the predominant degree awarded we identified the widest range of variation between predicted monetary outcomes, with the reference of less than 2 years differing by ampler amounts than the deviations observed between the regional categories. Controlling for all other variables and education levels, completion of a 2 year degree improved average predicted median income by \$5,892, while graduation with a bachelor's degree raised income by an average of \$15,670 after comparison to the baseline.

Though all of the regression coefficients for both numeric and categorical variables possessed p-values significant at the zero level (p \<2\*10-16), the multiple R2 value of 0.498 indicates that only approximately 50% of the variation observed in median earnings for those surveyed is accounted for by the collegiate attributes analyzed above. This is reflected by the substantial residual standard error of 8373 on 30,392 degrees of freedom, meaning that the predicted values produced by the linear model deviate from actual monetary outcomes by an average of \$8373. When compared to both the regression coefficients and the overall range of the actual median earnings values (\$8604-\$171900), the level of error observed in the estimates produced by the model is concerning and likely indicative of improper model fit through overfitting or multicollinearity.

## Improving the Model

#### Setting Up to Analyze the Models

```{r}
results <- data.frame()
analyze_model <- function(model){
  # testing the if errors zero on-average
  # closer to zero is good
  resid_avg_zero_test <- t.test(resid(model), mu=0)
  
  # testing for constant variance
  # closer to zero is better 
  heteroscedasticity_test <- bptest(model)
  
  # used for checking for overfitting
  #higher LOOR2 is better but R2 being much greater than LOOR2 incdicates overfitting
  LOOR2 <- rsq_loo(model)
  R2 <- summary(model)[["r.squared"]]
  
  
  # Ensure the types are compatible
  model_call_str <- as.character(paste(deparse(model$call), collapse = " "))
  resid_statistic <- as.numeric(resid_avg_zero_test$statistic)
  errors_zero_is_pass <-resid_avg_zero_test$p.value > .05
  bp_statistic <- as.numeric(heteroscedasticity_test$statistic)
  constant_variance_is_pass <- heteroscedasticity_test$p.value > .05
  loor2_value <- as.numeric(LOOR2)
  r2_value <- as.numeric(R2)

  # Append the new row 
  new_row <- data.frame(model=model_call_str, t=resid_statistic, errors_zero_is_pass, bp=bp_statistic, constant_variance_is_pass=constant_variance_is_pass,  R2=r2_value, LOOR2=loor2_value)
  
  # Making sure that the results are actually getting added
  results <<- rbind(results, new_row)
}
```

#### Accessing the Basic Model

```{r}
analyze_model(earnings_lm)
earnings_summary <- summary(earnings_lm)
R2 <- earnings_summary[["r.squared"]]
RSE <- earnings_summary$sigma
P.value <- pf(earnings_summary$fstatistic[1],earnings_summary$fstatistic[2],earnings_summary$fstatistic[3], lower.tail = FALSE)
print(cbind(`R2`, `RSE`, `P.value`))
```

Our Basic model is `earnings_med ~ region + degree + year + count_not_working + count_working`.
It had an $R^2$ of .493; this indicates that 49.3% of the variance of the data was accounted for by our model.
The basic model has a Residual Standard Error (RSE) of \$8372.924; this indicates that the average error of the basic model for all points is \~\$8372.924 (aka the predicted valuse are on average off by \$8372.924 from the expected values).

The F-test for the Basic model compares two hypotheses: the null hypothesis suggests that a simple intercept-only model is sufficient, while the alternative hypothesis argues that the Basic model is a better fit.
Given that the overall p-value is 0, which is below the threshold for statistical significance, we reject the null hypothesis.
This means the Basic model is more appropriate for this data than the intercept-only model.

```{r}
autoplot(earnings_lm)
t.test(resid(earnings_lm), mu=0)
bptest(earnings_lm)
```

In the diagnostic analysis of the basic model, the primary concern identified was the assumption of normality. The plots of residuals versus fitted values suggested ambiguity in confirming the mean-zero assumption. To clarify, a t-test on the residuals was conducted. The resulting p-value of 1 implies insufficient evidence to refute the null hypothesis, suggesting that the residuals are, on average, mean-zero.

Next, the assumption of constant variance was evaluated. Initial observations from the plot indicated homoscedasticity. However, a subsequent Breusch-Pagan test yielded a p-value significantly less than 2.2e-16. This result leads to the rejection of the null hypothesis of homoscedasticity, indicating the presence of heteroscedasticity in the model.

The final assumption under scrutiny is normality. The qqplot reveals clear deviations, with the data straying significantly from the expected 1-1 line, indicating issues with normality. However, given the substantial volume of data in the model, some might contend that the normality concern is less critical.

#### Transformations

The most important transformation for this data is to try the a log transformation since there primary issue is with constant variance.

```{r}
log_model <- lm(log(earnings_med) ~ region + degree + year + count_not_working + 
    count_working, data = scorecard)
analyze_model(log_model)

log_summary <- summary(log_model)
R2 <- log_summary[["r.squared"]]
RSE <- log_summary$sigma
P.value <- pf(log_summary$fstatistic[1],log_summary$fstatistic[2],log_summary$fstatistic[3], lower.tail = FALSE)
print(cbind(`R2`, `RSE`, `P.value`))
```

A log-dependent transformation was applied, resulting in the model: log(earnings_med) \~ region + degree + year + count_not_working + count_working. This transformation yielded a marginally improved \$R\^2\$ value of 0.503. The model's RSE is 0.243, indicating that the predicted values deviate on average by \$e\^{0.243}\$ from the expected values.The F-test for the Log Model, similar to the Basic model, compares an intercept-only model against the Log model. With a p-value of 0, the null hypothesis is rejected, suggesting that the Log model is more suitable for this data than the intercept-only model.

```{r}
autoplot(log_model)
t.test(resid(log_model), mu=0)
bptest(log_model)
```

For the Log model, the p-value is 1, providing insufficient evidence to reject the null hypothesis and suggesting that the residuals are mean-zero, similar to the Basic model. In terms of constant variance, the Log model's p-value is significantly below 2.2e-16. Moreover, the Log model displays a higher Breusch-Pagan statistic (1597) compared to the Basic model (855.68), indicating stronger evidence of heteroscedasticity.

While the Log model shows improvement in normality, this assumption is often considered less critical, leading to a perspective that its improvement is not significant.

Given the importance of assumptions, especially constant variance which is more significantly violated in the Log model as indicated by both plot and test, the log transformation is deemed not beneficial for use in this context.

#### Evidence Supporting the Inclusion of A Spline

```{r}
for(k in 1:5){
  formula_str <- sprintf("lm(earnings_med ~ region + degree + year + ns(count_not_working, df=%d) + ns(count_working, df=%d), data=scorecard)", k,k)
  spine_both_model <- eval(parse(text = formula_str))
  analyze_model(spine_both_model)
  
  formula_str <- sprintf("lm(earnings_med ~ region + degree + year + ns(count_not_working*count_working, df=%d), data=scorecard)", k)
  spine_both_int_model <- eval(parse(text = formula_str))
  analyze_model(spine_both_model)
  
  
  formula_str <- sprintf("lm(log(earnings_med) ~ region + degree + year + ns(count_not_working, df=%d) + ns(count_working, df=%d), data=scorecard)", k,k)
  spine_both_model <- eval(parse(text = formula_str))
  analyze_model(spine_both_model)
  
  formula_str <- sprintf("lm(log(earnings_med) ~ region + degree + year + ns(count_not_working*count_working, df=%d), data=scorecard)", k)
  spine_both_int_model <- eval(parse(text = formula_str))
  analyze_model(spine_both_model)
}
```

None of the splines have a significantly good impact on the model, so we will not include one in our model !!!
TODO this is a lie???
because i was being dumb

#### Interpret Interaction

There is likely an interaction between count_not_working, count_working, and year.

```{R}
count_year_int_model <- lm(earnings_med ~ region + degree + (count_not_working + count_working) * year, data=scorecard)
summary(count_year_int_model)
analyze_model(count_year_int_model)
anova(earnings_lm, count_year_int_model)
drop1(count_year_int_model, test = "F") # TODO FIX FORMATTING FOR THIS AREA
```

The model predicts that for every 1 increase in count_not_working that the effect of year will increase 6.179e-01 units.
The model also predicts for every 1 unit increase in count_working that the effect of year will decrease 7.314e-02 units.

```{r}
results <- na.omit(results)
results$row_names <- row.names(results)
results <- results[order(-results$LOOR2), ]
results$row_names <- factor(results$row_names, levels = results$row_names)

# Plot for 't'
ggplot(results, aes(x = row_names, y = t)) + 
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("t values")


# Create a transformation for 'LOOR2'
max_bp <- max(results$bp, na.rm = TRUE)
max_LOOR2 <- max(results$LOOR2, na.rm = TRUE)
scale_factor <- max_bp / max_LOOR2

# Apply the unified scaling to both LOOR2 and R2
results$LOOR2_scaled <- results$LOOR2 * scale_factor

# Update melting to include both scaled LOOR2 and R2
long_results <- melt(results, id.vars = "row_names", measure.vars = c("bp", "LOOR2_scaled"))

# Update variable names for the legend
long_results$variable <- factor(long_results$variable, labels = c("BP", "Scaled LOOR2"))

# Plot
ggplot(long_results, aes(x = row_names, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  scale_fill_manual(values = c("BP" = "#87CEFA", "Scaled LOOR2" = "#FF6A6A")) +
  scale_y_continuous("BP", sec.axis = sec_axis(~ . / scale_factor, name = "Scaled LOOR2")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("BP and Scaled LOOR2 for each model") +
  labs(x = "Row Names", y = "BP Value", fill = "Variable")

results[1,]
best_model <- eval(parse(text=results[1,"model"]))
summary(best_model)
autoplot(best_model)
```

## Formal Hypothesis Tests

To begin the project, we wanted to investigate how the number of working graduates (`count_working`), region of the university (`region`), and degree type (`degree`) relate to the median income of graduates (`earnings_med`).
In this section, we tested if each of these three variables are significant in predicting the median income.
Firstly, we used the following equation to represent the relationship between median earnings and the chosen predictors: $$
Y = \beta_0 + \beta_{r_1}X_{r_1} + \beta_{r_2}X_{r_2} + \beta_{r_3}X_{r_3} + \beta_{d_1}X_{d_2} + \beta_{d_2}X_{d_2} + \beta_yX_y + \beta_nX_n + \beta_wX_w + \epsilon
$$ Where: $Y$ = `earnings_med` , $X_r$ = `region`, $X_d$ = `degree`, $X_y$ = `year`, $X_n$ = `count_not_working`, and $X_w$ = `count_working` Using our final model, `earnings_lm`, we performed the following hypotheses testing:

For `region`:

-   $H_0$: $\beta_{r_1} = \beta_{r_2} = \beta_{r_3} = 0$

-   $H_a$: $\beta_{r1} \ne \beta_{r2} \ne \beta_{r3} \ne 0$

For `degree`:

-   $H_0$: $\beta_{d_1} = \beta_{d_2} = 0$

-   $H_a$: $\beta_{d_1} \ne \beta_{d_2} \ne 0$

For `count_working`:

-   $H_0$: $\beta_w = 0$

-   $H_a$: $\beta_w \ne 0$

Using the p-values from the `drop1` function, we see that $\beta_r$, $\beta_g$, and $\beta_w$ are all significant predictors of `earnings_med`.

```{r}
drop1(earnings_lm, test = "F")
```

Furthermore, using the `summary` functions we see that $\beta_{r_1}$, $\beta_{r_2}$, $\beta_{r_3}$, $\beta_{d_1}$, and $\beta_{d_2}$ are all significant predictors of $Y$.
We therefore reject H_0 for both `region` and `degree` and conclude that median income changes based on the regional location of the college and the type of degree the college offers.
Also, we see that there is significant evidence that $\beta_w$ is positive (which confirms our hypothesis in Part 1).
We therefore reject $H_0$ for `count_working` variable and conclude that median earnings tend to increase as the number of working graduates increases.

```{r}
summary(earnings_lm)
```

To further investigate the `region` and `degree` variables, we ran the respective `constrast` functions and found that income significantly varies between all regions as well as between all degree types which confirms our initial hypothesis stated in Part 1.

```{r}
cat("Comparing median income between regions:", "\n")
contrast(emmeans(earnings_lm, ~ region), method = "pairwise", adjust = "none")
cat("\n","Comparing median income between degrees:", "\n", sep = "")
contrast(emmeans(earnings_lm, ~ degree), method = "pairwise", adjust = "none")
```

In conclusion, based on our findings, all of our initial hypotheses seem to be confirmed.
The median earnings seem to increase with the number of graduates that are able to find a job.
The earnings also vary based on degree type the graduate received and the geographic region of the US where the college is located.
These conclusions do have serious limitations though.
Firstly, our model contained only 5 predictors all of which were found to be significant.
However, the inclusion of more predictors can affect the trends of the model and change the significance of each of the original 5 predictors.
Also, we need to consider the possibility of existence of confounding variables.
For example, it is possible that graduates who go to elite colleges are more likely to both find a job and earn a higher wage.
Along with this, some regions in the US, like the Northeast, tend to have many states with a significantly higher cost of living which can explain the difference in median earnings.
It is also important to account for the fact that we performed multiple tests in this section, hence we adjusted our p-values using the Bonferroni correction.
Firstly, for both region and degree variables, we repeated the pairwise comparisons using the Bonferroni adjusted p-values.
In both cases, our conclusions did not change.

```{r}
cat("Comparing median income between regions:", "\n")
contrast(emmeans(earnings_lm, ~ degree), method = "pairwise", adjust = "bonferroni")
cat("\n", "Comparing median income between degrees:", "\n", sep="")
contrast(emmeans(earnings_lm, ~ region), method = "pairwise", adjust = "bonferroni")
```

Then, since we tested three separate sets of hypotheses, the resulting p-values had to be multiplied by a factor of 3 to perform the Bonferroni correction.
However, in all three cases we ended up with a $p-value < 2 * 10^{-16}$ so it follows that we still must reject $H_0$ in all three cases.

## Robustness of Results

#### Compute Bootstrap Standard Errors

```{r}
earnings_boot <- lm.boot(earnings_lm, R=500,000)
summary(earnings_boot)

## Compute the T-statistic
t_boot <- coef(earnings_lm) / summary(earnings_boot)[["stdev.params"]]
t_orig <- coef(earnings_lm) / summary(earnings_lm)$coefficients[,2]

## Compute the P-values
p_boot <- 2 * pt(abs(t_boot), df = earnings_lm$df.residual, lower.tail = FALSE)
p_orig <- 2 * pt(abs(t_orig), df = earnings_lm$df.residual, lower.tail = FALSE)

## Print T statistics and P-values
print(cbind(`sd-orig` = summary(earnings_lm)$coefficients[,2], `sd-boot` = summary(earnings_boot)[["stdev.params"]], `boot - orig`=summary(earnings_boot)[["stdev.params"]]-summary(earnings_lm)$coefficients[,2], `diff / o (%)`=(summary(earnings_boot)[["stdev.params"]]-summary(earnings_lm)$coefficients[,2])/ summary(earnings_lm)$coefficients[,2] * 100))
print(cbind(`t-orig` = t_orig, `P-orig` = p_orig, `t-boot` = t_boot, `P-boot` = p_boot))
```

All of the coefficients are very closely related and not outside of a magnitude of each other.
The largest change was in degree 2, with a percent change of -2.83.
Due to the close relation, they appear to suggest no issues.

#### Leave-one-out Prediction Error

```{r}

LOOR2 <- rsq_loo(earnings_lm)
R2 <- summary(earnings_lm)[["r.squared"]]

print(cbind(`LOOR2`=LOOR2, `R2`=R2))
```

There does not appear to be evidence that the model is overfit.

#### Check for Influential Points

```{r}

ap <- autoplot(earnings_lm)
ap[4]
# using 
influencePlot(earnings_lm)
ip <- influencePlot(earnings_lm)
hip <- as.numeric(row.names(ip))
earnings_lm$model[hip,]
```

#### Multicolinearity

```{r}
numeric_df <- do.call(data.frame, lapply(earnings_lm$model, FUN = as.numeric.l))
pheatmap(cor(numeric_df), treeheight_col = 0, treeheight_row = 0, display_numbers = TRUE, breaks = seq(-1, 1, length = 101))


vif_values <- vif(earnings_lm)
print(vif_values)

# redoing with better lm

earnings_lm <- lm(earnings_med~region+degree+year+count_not_working, data=scorecard)
numeric_df <- do.call(data.frame, lapply(earnings_lm$model, FUN = as.numeric.l))
pheatmap(cor(numeric_df), treeheight_col = 0, treeheight_row = 0, display_numbers = TRUE, breaks = seq(-1, 1, length = 101))


vif_values <- vif(earnings_lm)
print(vif_values)


```

There is high multicolinearity between count_working and count_not_working.
This is also indicated by the high vif for each.
Once one of the variables is removed the vifs become more balanced and within 1 of each other.

## Conclusions

We rejected the null hypotheses of our initial analysis of the data in favor of our alternative hypotheses, which stated that median income differed due to number of working graduates, region, or degree earned. We also found that the correlations between the variables are quite weak. Specifically, it seemed that median earnings increased with the number of working graduates, varied between U.S. regions, and varied between length of degree earned. However, inclusion of more predictors could affect the trends of the model, and there could be confounding variables which could be influencing the trends and results of the tests. 

In fitting the model we found that not working and year are both significantly negatively associated with median income. We also found that when held against graduates of Northeastern schools, graduates of Southern, North Central, and Western schools all have decreased median income. When compared to graduates with a less-than-2-year degree, those with a 2 year degree and 4 or more year degree saw increased median earnings. This model however, saw that only about 50% of the variation observed in median earnings was accounted for, meaning that the model is likely improperly fit through overfitting or multicollinearity. 

In discovering the improperness of the original model fit, we used a log-dependant transformation in order to see an improvement in fit appropriateness. We found that the log-transformed model had a better appropriateness than the model previously used, as there were fewer violations of model assumptions.  

